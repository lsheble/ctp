{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "last updated Jun 10 2019\n",
    "@author: ShebleAdmin\n",
    "query crossref with a list of bibliographic entries, use when bibliographic data has a range of formats / is irregular\n",
    "\n",
    "scores from crossref seem to work pretty well as estimate of likelihood of match,\n",
    "even with data that is somewhat rough. use of quotes within publications\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review: requests version \n",
    "requests.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/filename_to_write_data_to.csv\"\n",
    "#### Set fp variable to your folder with file to be processed ####\n",
    "#fp = \"/<path_to_file_with_jumble of references>/\" \n",
    "fp = \"my_directory/\"\n",
    "\n",
    "# add file name to file path\n",
    "examples = fp + \"file_name of file with input data to be processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### identify user - let crossref know who is using their service\n",
    "headers = {\n",
    "    'User-Agent': 'user-agent-value', # update with value for User-Agent\n",
    "    'From': 'me@example.org'}       # update to include contact email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query_url(citation):\n",
    "    query_url = \"http://api.crossref.org/works?query=\"\n",
    "#    citation = re.sub('[&,.()\\[\\]:/\"+Õ\\_@Ò\\*\\n]', '', citation)\n",
    "#    added line below to include row numbers for input data. number is retained for tracking.\n",
    "#       here, references may be preceded by a number of 0-3 digits, a period, and 0 to 3 spaces... this number is saved for the output later\n",
    "    citation = re.sub(r'^\\d{0,3}\\.{0,1} {0,3}', ' ', citation)\n",
    "    citation = re.sub('[^\\s\\da-zA-Z-/]', ' ', citation)\n",
    "    citation = re.sub(r'\\s\\D{1,2}\\s{0,1}\\D{0,1}\\s', ' ', citation)\n",
    "    citation = re.sub(r'\\s{2,10}', ' ', citation)\n",
    "    citation = re.sub(r'\\d-\\d', ' ', citation)\n",
    "    citation = re.sub(r'$\\d-\\d', ' ', citation)\n",
    "    citation.strip(' ')    \n",
    "    query_url = query_url + '\"' + citation + '\"' + '&rows=1' # &rows=1 limits to the first result (&rows=0 to get a summary of search results)\n",
    "    return query_url\n",
    "\n",
    "''' \n",
    "data from specific json fields retrieved from crossref is parsed and output to a flat file via pandas. \n",
    "\n",
    "'''\n",
    "\n",
    "# THIS ONE WORKS BEST AT THE MOMENT think about doing something else with the affiliation data (but there was essentially none in some of my data)\n",
    "def construct_author(author_item):\n",
    "    count = 0\n",
    "    author_construct = ''\n",
    "    affiliation_construct = ''\n",
    "    for item in author_item:\n",
    "        if count < (len(author_item)-1):\n",
    "            if 'family' in item:\n",
    "                author_construct = author_construct + str(item['family']) \n",
    "            else:\n",
    "                 author_construct = author_construct + \"no_family_name\"\n",
    "            if 'given' in item:\n",
    "                author_construct = author_construct  + ', ' + str(item['given'])\n",
    "            else:\n",
    "                 author_construct = author_construct + ', ' + \"no_given_name\"\n",
    "            if 'sequence' in item:\n",
    "                author_construct = author_construct + ', ' + str(item['sequence'])\n",
    "            else:\n",
    "                author_construct = author_construct + ', ' + u'NA'\n",
    "            au_affiliation = ''\n",
    "            if 'affiliation'[0] in item:\n",
    "                if 'name' in item['affiliation'][0] and len(item['affiliation'][0]) == 1:\n",
    "                    au_affiliation = au_affiliation + item['affiliation'][0]['name']\n",
    "                    print(item['affiliation'][0]['name'], ' : ', au_affiliation)\n",
    "                elif 'name' not in item['affiliation'][0]:\n",
    "                    au_affiliation = u'NA'\n",
    "                else:\n",
    "                    afct = ''\n",
    "                    afct = afct + str(len(item['affiliation'][0]))\n",
    "                    au_affiliation = au_affiliation + afct + \" (multiple affiliations)\"\n",
    "                author_construct = author_construct + ': ' + au_affiliation\n",
    "\n",
    "            else:\n",
    "                au_affiliation = u'NA'\n",
    "                author_construct = author_construct + ': ' + au_affiliation \n",
    "            author_construct = author_construct + '; '                  \n",
    "            count += 1\n",
    "    return author_construct\n",
    "    \n",
    "    \n",
    "           \n",
    "\n",
    "def construct_subject(subject_item):\n",
    "    count=0\n",
    "    subject_construct = ''\n",
    "    for item in subject_item:\n",
    "        if count < (len(subject_item)-1):\n",
    "            subject_construct = subject_construct + item + '; '\n",
    "            count += 1\n",
    "        else:\n",
    "            subject_construct = subject_construct + item\n",
    "            count += 1\n",
    "    return subject_construct\n",
    "\n",
    "    \n",
    "# cite_no is used to retain the row number that precedes the bibliographic reference item\n",
    "def extract_json_fields(data, cite_no):\n",
    "    reference = []\n",
    "    # doi = data['message']['items'][0]['DOI']\n",
    "    if 'DOI' in data['message']['items'][0]:\n",
    "        doi = data['message']['items'][0]['DOI']\n",
    "    else: \n",
    "        doi = u'NA'\n",
    "    year = str(data['message']['items'][0]['issued']['date-parts'][0][0])\n",
    "    # number of subjects may range from 0 to many\n",
    "    if 'subject' in data['message']['items'][0]:\n",
    "        subject = construct_subject(data['message']['items'][0]['subject'])\n",
    "    else: \n",
    "        subject = u'NA'\n",
    "    if 'author' in data['message']['items'][0]:\n",
    "        author = construct_author(data['message']['items'][0]['author'])\n",
    "    else:\n",
    "        author = u'NA'\n",
    "    if 'score' in data['message']['items'][0]:    \n",
    "        score = data['message']['items'][0]['score']\n",
    "    else:\n",
    "        score = u'NA'\n",
    "    if 'volume' in data['message']['items'][0]:\n",
    "        volume = data['message']['items'][0]['volume']\n",
    "    else:\n",
    "        volume = u'NA'\n",
    "    if 'issue' in data['message']['items'][0]:\n",
    "        issue = data['message']['items'][0]['issue']\n",
    "    else:\n",
    "        issue = u'NA'\n",
    "    # some items don't have a title, so make this optional...        \n",
    "    if 'title' in data['message']['items'][0]:\n",
    "        title = data['message']['items'][0]['title'][0]\n",
    "    else:\n",
    "        title = u'NA'\n",
    "    if 'alternative-id' in data['message']['items'][0]:\n",
    "        alternative_id = data['message']['items'][0]['alternative-id'][0]\n",
    "    else:\n",
    "        alternative_id = u'NA'\n",
    "    # expand for items without a container title... data I've retrieved has had 0-1 container titles (e.g. jrnl of pub)\n",
    "    if 'container_title' in data['message']['items'][0]:\n",
    "        container_title = data['message']['items'][0]['container-title'][0]\n",
    "    else:\n",
    "        container_title = u'NA'\n",
    "    if 'page' in data['message']['items'][0]:\n",
    "        page = data['message']['items'][0]['page']\n",
    "    else:\n",
    "        page = u'NA'\n",
    "    # order retrieved & extracted data for each reference\n",
    "    reference.extend([cite_no, subject, author, year, title, container_title, volume, issue, page, doi, alternative_id, score])\n",
    "    return reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(examples, sep=',', header=0, verbose=True, quotechar='\"',  error_bad_lines=True, warn_bad_lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = df['citestring'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2 empty lists, one for returned data rows, and one for errors\n",
    "rows = []\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in citations:\n",
    "    item.strip(' ') \n",
    "    cite_no = ''\n",
    "    # keep the number included in my input data... rows looked like this in pandas:\n",
    "    '''\n",
    "    0\t1. Clearing the Air: A systematic review on th...\n",
    "    1\t2. E-Cigarette Presentation by the American As...\n",
    "'''\n",
    "    m = re.match(r'(?P<number>^\\d{1,4})\\.{0,1} {0,3}', item) \n",
    "    if m:\n",
    "        cite_no = m.group(1)\n",
    "\n",
    "    else:\n",
    "        cite_no = \"unknown\"\n",
    "    query_item = build_query_url(item)\n",
    "    request = requests.get(query_item, headers = headers)\n",
    "    #print(request.text)\n",
    "    try:    \n",
    "        refs = request.text\n",
    "    except:\n",
    "        errors.append('no text from crossref')\n",
    "        print(errors)\n",
    "        print(\"cite_no: {}, error code: {} \\n\".format(cite_no, response.status_code))\n",
    "    #print(refs)\n",
    "    \n",
    "    if refs:\n",
    "        data = json.loads(refs.strip())\n",
    "        data_extract = extract_json_fields(data, cite_no)\n",
    "        rows.append(data_extract)\n",
    "    else:\n",
    "        print(\"cite_no: {}, error code: {} \\n\".format(cite_no, response.status_code))\n",
    "        rows.append([cite_no, response.status_code])\n",
    "    # sleeping between api calls... length of sleep could be shortened\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check: count of rows of retrieved data\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a few rows\n",
    "rows[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see format of most recently retrieved data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refs = pd.DataFrame(rows)\n",
    "df_refs.columns = ['ref_no', 'subject', 'author: affiliation', 'year', 'title', 'journal', 'volume', 'issue', 'page', 'doi', 'alternative_id', 'score']\n",
    "# review the data\n",
    "df_refs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data) \n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.concat([ df, df_refs], axis=1)\n",
    "df_out[['citestring', 'ref_no', 'author: affiliation', 'title']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to tab-separated tsv\n",
    "df_out.to_csv(\"my_directory/filename_to_write_data_to.csv\", sep='\\t', header=True, index_label='row_no', na_rep = 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
